1. Сбор данных
    - Проведен сбор данных и изучены основные характеристики нашего датасета.


2. Очистка данных
    - В процессе анализа были обнаружены дубликаты в столбце комментариев.
    - Проведена очистка данных: сохранены строки с максимальным значением toxicity_annotator_count.
    - Это позволило избежать повторов для дальнейшего изучения данных и построения модели.

3. Анализ пороговости токсичности комментариев
    - Мы подробно исследовали какой порог токсичности можно считать оптимальным. Исследователи Kaggle kaggle competition предлагали использовать значение 0.5 однако мы удостоверились, что существует меньшее значение начиная с которого можно было бы отнести текст к позитивному классу - 0.4
    ![toxicity_0_1.png](images/toxicity_0_1.png)
    ![toxicity_0_2.png](images/toxicity_0_2.png)
    ![toxicity_0_4.png](images/toxicity_0_4.png)
    ![toxicity_0_5.png](images/toxicity_0_5.png)
    
    Вывод 
        - Для значений порога 0.1 и 0.2 различия между negative и positive labeled корпусами просматриваются слабо.
        - На значении 0.4 различия становятся заметными, особенно хорошо видно на облаках слов. В текстах начинает присутствовать сарказм, резко негативные оценочные суждения, большое количество пунктуации (многоточия, вопросительные знаки).

4. Анализ поведения каждого признака в отдельности, его связь с целевой переменной, а также попарные корреляции
    - Проведен временной анализ комментариев
      - Пришли к выводу что количество как обычных, так и токсичных комментариев увеличивается со временем. Доля токсичных комментариев возросла с 6.6% до 8.7% в период с марта по октябрь 2016 года.
      ![comments_datetime_2.png](images/comments_datetime_2.png)
      ![comments_datetime.png](images/comments_datetime.png)

   - Проанализирована токсичность комментариев в течение суток
     - Пришли к выводу что доля токсичных комментариев начинает повышаться с 23:00, достигая пика в 9% к 8:00.  
     - ![comments_toxicity_in_a_day..png](images/comments_toxicity_in_a_day.png)
     
   - Мы также проводили исследование доли аннотаторов которые отметили упоминание социальных идентичностей связанных с переменными female, male, white, black, muslim, homosexual_gay_or_lesbian и т.д.
      - И можно сделать вывод что для токсичных комментариев доли таких аннотаторов выше, чем для обычных, а для переменной christian средняя доля выше для обычных комментариев. Некоторые идентичности, такие как buddhist и hindu, упоминаются редко в обоих типах комментариев.
      ![annotators_shares_in_social_groups.png](images/Fannotators_shares_in_social_groups.png)
   
   - Проведен анализ эмодзи и заглавных букв (КАПС) 
     - Вывод - эмодзи не влияют на токсичность, но заглавные буквы встречаются в токсичных комментариях, список наиболее популярных капс-слов составлен. 
     - ![toxic_not_toxic_caps.png](images/toxic_not_toxic_caps.png)

   - В рамках анализа связи реакций и токсичности (0 это обычные комментарии а 1 токсичные)
     - Можно сделать увидеть отсутствие прямой корреляции, кроме реакции лайков.
       ![reactions.png](images/reactions.png)
     - Это также подтверждается таблицой корелляции
     - ![corellation_table_reactions.png](images/corellation_table_reactions.png)

   - Проведен анализ токсичности и ее подтипов, составлена таблица корреляции. 
     - Вывод - переменная toxicity наиболее сильно коррелирует с threat и умеренно с obscene и identity_attack
       ![corellation_table.png](images/corellation_table.png)

   - Исследовано наличие ссылок в комментариях: всего 3% обычных и 1.3% токсичных комментариев содержат ссылки, связи с токсичностью не выявлено.

   - Анализ длины комментариев показал, что в обычных комментариях больше длинных сообщений (более 950 символов).

5. Начата работа по NLP, включая токенизацию, обработку текста и анализ частей речи, с фокусом на связи между длиной комментариев и их токсичностью.