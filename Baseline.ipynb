{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve, auc, mean_squared_error, mean_absolute_error\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = pd.read_csv('modified_train.csv', index_col=0)",
   "id": "b23e5222ed87c679",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.columns",
   "id": "cd7897eecd8e59ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[df.toxicity_b == 0].shape",
   "id": "c9b0f10073fb8bed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[df.toxicity_b == 1].shape\n",
   "id": "5c5017b5d60cb0ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print('Процентное соотношение значений ' + str(df['toxicity_b'].value_counts(normalize=True) * 100))",
   "id": "4b319fe140d12f6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['ctws'].fillna('', inplace=True)",
   "id": "28c18c9849efb05d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Одноклассовая класификация",
   "id": "8f75eeca4ca60f45"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Обучение моделей",
   "id": "e6eacbe9d55aaf74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = df['ctws']\n",
    "y = df['toxicity_b']"
   ],
   "id": "1b555dde7e48f7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Параметр stratify используется для того, чтобы гарантировать, что распределение целевой переменной y (или другого указанного массива) в выборках train и test будет аналогичным.",
   "id": "397f0cf6455f3fb3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ],
   "id": "ec58deb51e6444ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Функция обучения модели и предсказания и визуализации результатов\n",
    "def train_and_predict_toxicity(model, X_train, X_test, y_train):\n",
    "    #Обучение модели\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Предсказание классов\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # Предсказание вероятностей классов (если доступно)\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        # Вероятности для положительного класса\n",
    "        y_pred_proba_train = model.predict_proba(X_train)[:, 1]\n",
    "        y_pred_proba_test = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_pred_proba_train = None\n",
    "        y_pred_proba_test = None\n",
    "\n",
    "    return y_pred_train, y_pred_test, y_pred_proba_train, y_pred_proba_test\n",
    "\n",
    "\n",
    "# Функция для отображения метрик\n",
    "def show_metrics(y_train, y_test, y_pred_train, y_pred_test, y_pred_proba_train, y_pred_proba_test, title):\n",
    "    # Вычисляем точность (precision) — доля истинных положительных среди всех предсказанных положительных\n",
    "    # одна из метрик, оценивающих качество решения задачи бинарной классификации в машинном обучении. \n",
    "    # Она давно себя зарекомендовала: это одно интерпретируемое и легко вычисляемое число, оценивающее качество алгоритма\n",
    "    precision_train = precision_score(y_train, y_pred_train)\n",
    "    precision_test = precision_score(y_test, y_pred_test)\n",
    "\n",
    "    # Вычисляем полноту (recall) — доля истинных положительных среди всех фактических положительных\n",
    "    recall_train = recall_score(y_train, y_pred_train)\n",
    "    recall_test = recall_score(y_test, y_pred_test)\n",
    "\n",
    "    # Вычисляем F1-метрику — гармоническое среднее между точностью и полнотой\n",
    "    f1_train = f1_score(y_train, y_pred_train)\n",
    "    f1_test = f1_score(y_test, y_pred_test)\n",
    "    \n",
    "    # посчитать MSE, MAE, RMSE\n",
    "\n",
    "    # Вычисляем среднеквадратичную ошибку (MSE) — среднее значение квадратов разностей между фактическими и предсказанными значениями\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "    # Вычисляем среднюю абсолютную ошибку (MAE) — среднее значение абсолютных разностей между фактическими и предсказанными значениями\n",
    "    mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "    # Вычисляем квадратный корень из MSE (RMSE) — интерпретация MSE в тех же единицах, что и данные\n",
    "    rmse_train = np.sqrt(mse_train)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "    \n",
    "\n",
    "    print(title + '\\n')\n",
    "\n",
    "    print('Precision\\t\\tRecall\\t\\t\\tF1\\n')\n",
    "    print(f'Train: {precision_train:.2f}\\t\\tTrain: {recall_train:.2f}\\t\\tTrain: {f1_train:.2f}')\n",
    "    print(f'Test: {precision_test:.2f}\\t\\tTest: {recall_test:.2f}\\t\\tTest: {f1_test:.2f}')\n",
    "\n",
    "\n",
    "    # Выводим таблицу с метриками MSE, MAE и RMSE\n",
    "    print('\\nMSE\\t\\t\\tMAE\\t\\t\\tRMSE\\n')\n",
    "    print(f'Train: {mse_train:.2f}\\tTrain: {mae_train:.2f}\\tTrain: {rmse_train:.2f}')\n",
    "    print(f'Test: {mse_test:.2f}\\tTest: {mae_test:.2f}\\tTest: {rmse_test:.2f}')\n",
    "\n",
    "    def show_confusion_matrix(y_true, y_pred, sample_name, ax):\n",
    "        # Вычисляем матрицу ошибок (confusion matrix) с нормализацией по всем элементам\n",
    "        # Это показывает пропорции вместо абсолютных значений\n",
    "        cm = confusion_matrix(y_true, y_pred, normalize='all')\n",
    "\n",
    "        # Определяем метки классов для отображения в матрице\n",
    "        labels = ['Non-Toxic (0)', 'Toxic (1)']\n",
    "        # Преобразуем матрицу ошибок в DataFrame для удобной визуализации\n",
    "        cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "\n",
    "        # Создаем тепловую карту (heatmap) на основе матрицы ошибок    \n",
    "        sns.heatmap(cm_df, annot=True, fmt=\".2%\", cmap='twilight_shifted', ax=ax)\n",
    "        ax.set_title(f'Confusion matrix ({sample_name})')\n",
    "        ax.set_xlabel('Predicted')\n",
    "        ax.set_ylabel('True')\n",
    "\n",
    "    def show_roc_curve(y_true, y_pred_proba, model_name, sample_name, ax):\n",
    "        # Вычисляем значения FPR (False Positive Rate) и TPR (True Positive Rate)\n",
    "        # на различных порогах классификации\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "        # Вычисляем площадь под кривой (AUC, Area Under Curve)\n",
    "        auc = roc_auc_score(y_true, y_pred_proba)\n",
    "        \n",
    "        # Строим ROC-кривую, отображая FPR по оси X, а TPR по оси Y\n",
    "        ax.plot(fpr, tpr)\n",
    "        # Добавляем диагональную линию (y = x) для ориентира (случайная модель)\n",
    "        ax.plot([0, 1], [0, 1], 'k--')\n",
    "        ax.set_xlabel('FPR')\n",
    "        ax.set_ylabel('TPR')\n",
    "        ax.set_title(f'{model_name} ({sample_name}) ROC (AUC = {auc:.2f})')\n",
    "        # Включаем сетку для удобства чтения графика\n",
    "        ax.grid(True)\n",
    "\n",
    "    # Строит кривую Precision-Recall (точность-полнота).\n",
    "    def show_pr_curve(y_true, y_pred_proba, model_name, sample_name, ax):\n",
    "        # Вычисляем значения precision (точности) и recall (полноты) для различных порогов\n",
    "        precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)\n",
    "        # Вычисляем площадь под кривой Precision-Recall (AUC-PR)\n",
    "        auc_pr = auc(recall, precision)\n",
    "\n",
    "        # Строим график кривой Precision-Recall\n",
    "        ax.plot(recall, precision)\n",
    "        ax.set_xlabel('Recall')\n",
    "        ax.set_ylabel('Precision')\n",
    "        ax.set_title(f'{model_name} ({sample_name}) Precision-Recall Curve (AUC = {auc_pr:.2f})')\n",
    "        ax.grid(True)\n",
    "\n",
    "    # Проверяем, есть ли предсказания вероятностей для тренировочной и тестовой выборок\n",
    "    if y_pred_proba_train is not None and y_pred_proba_test is not None:\n",
    "        _, axs = plt.subplots(3, 2, figsize=(16, 18))\n",
    "\n",
    "        # Показываем матрицу ошибок для тренировочной и тестовой выборок\n",
    "        show_confusion_matrix(y_train, y_pred_train, 'Train', axs[0, 0])\n",
    "        show_confusion_matrix(y_test, y_pred_test, 'Test', axs[0, 1])\n",
    "\n",
    "        # Показываем ROC-кривые для тренировочной и тестовой выборок\n",
    "        show_roc_curve(y_train, y_pred_proba_train, title, 'Train', axs[1, 0])\n",
    "        show_roc_curve(y_test, y_pred_proba_test, title, 'Test', axs[1, 1])\n",
    "\n",
    "        # Показываем кривые Precision-Recall для тренировочной и тестовой выборок\n",
    "        show_pr_curve(y_train, y_pred_proba_train, title, 'Train', axs[2, 0])\n",
    "        show_pr_curve(y_test, y_pred_proba_test, title, 'Test', axs[2, 1])\n",
    "    else:\n",
    "        # Если предсказаний вероятностей нет, создаем сетку из 1 строки и 2 столбцов (2 графика)\n",
    "        _, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "        show_confusion_matrix(y_train, y_pred_train, 'Train', axs[0])\n",
    "        show_confusion_matrix(y_test, y_pred_test, 'Test', axs[1])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Функция получения мешка слов\n",
    "def get_bows(X_train, X_test):\n",
    "    vectorizer = CountVectorizer()\n",
    "    return vectorizer.fit_transform(X_train), vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "# Векторизация  TF-IDF\n",
    "def get_tfidf(X_train, X_test):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    return vectorizer.fit_transform(X_train), vectorizer.transform(X_test)"
   ],
   "id": "b56cfe39fe52def",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Обучение с мешком слов",
   "id": "c37bbb0d46c1fcba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train_bow, X_test_bow = get_bows(X_train, X_test)",
   "id": "b8142e74973efb58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Логистическая регрессия\n",
   "id": "59ed1f1701a909ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "(\n",
    "    y_log_reg_bow_pred_train,\n",
    "    y_log_reg_bow_pred_test,\n",
    "    y_log_reg_bow_pred_proba_train,\n",
    "    y_log_reg_bow_pred_proba_test\n",
    ") = train_and_predict_toxicity(\n",
    "    model=LogisticRegression(max_iter=1000),\n",
    "    X_train=X_train_bow,\n",
    "    X_test=X_test_bow,\n",
    "    y_train=y_train,\n",
    ")"
   ],
   "id": "c3beebfe952cf94e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "show_metrics(\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    y_pred_train=y_log_reg_bow_pred_train,\n",
    "    y_pred_test=y_log_reg_bow_pred_test,\n",
    "    y_pred_proba_train=y_log_reg_bow_pred_proba_train,\n",
    "    y_pred_proba_test=y_log_reg_bow_pred_proba_test,\n",
    "    title='LogisticRegression BoW'\n",
    ")"
   ],
   "id": "6ec19e9f83540431",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SVM",
   "id": "e4a2182a54cb17fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "(\n",
    "    y_linear_svc_bow_pred_train,\n",
    "    y_linear_svc_bow_pred_test,\n",
    "    y_linear_svc_bow_pred_proba_train,\n",
    "    y_linear_svc_bow_pred_proba_test\n",
    ") = train_and_predict_toxicity(\n",
    "    model=LinearSVC(dual=False),\n",
    "    X_train=X_train_bow,\n",
    "    X_test=X_test_bow,\n",
    "    y_train=y_train,\n",
    ")"
   ],
   "id": "c9b9e80fbfdc1e29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T06:37:48.212956Z",
     "start_time": "2024-12-03T06:37:46.699756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "show_metrics(\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    y_pred_train=y_linear_svc_bow_pred_train,\n",
    "    y_pred_test=y_linear_svc_bow_pred_test,\n",
    "    y_pred_proba_train=y_linear_svc_bow_pred_proba_train,\n",
    "    y_pred_proba_test=y_linear_svc_bow_pred_proba_test,\n",
    "    title='SVM BoW'\n",
    ")"
   ],
   "id": "394ccb5385ee6b2f",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[41], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mshow_metrics\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_pred_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_linear_svc_bow_pred_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_pred_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_linear_svc_bow_pred_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_pred_proba_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_linear_svc_bow_pred_proba_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_pred_proba_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_linear_svc_bow_pred_proba_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtitle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mSVM BoW\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\n\u001B[1;32m      9\u001B[0m \u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[18], line 27\u001B[0m, in \u001B[0;36mshow_metrics\u001B[0;34m(y_train, y_test, y_pred_train, y_pred_test, y_pred_proba_train, y_pred_proba_test, title)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mshow_metrics\u001B[39m(y_train, y_test, y_pred_train, y_pred_test, y_pred_proba_train, y_pred_proba_test, title):\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;66;03m# Вычисляем точность (precision) — доля истинных положительных среди всех предсказанных положительных\u001B[39;00m\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;66;03m# одна из метрик, оценивающих качество решения задачи бинарной классификации в машинном обучении. \u001B[39;00m\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;66;03m# Она давно себя зарекомендовала: это одно интерпретируемое и легко вычисляемое число, оценивающее качество алгоритма\u001B[39;00m\n\u001B[0;32m---> 27\u001B[0m     precision_train \u001B[38;5;241m=\u001B[39m \u001B[43mprecision_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m     precision_test \u001B[38;5;241m=\u001B[39m precision_score(y_test, y_pred_test)\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;66;03m# Вычисляем полноту (recall) — доля истинных положительных среди всех фактических положительных\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/sklearn/utils/_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m    211\u001B[0m         )\n\u001B[1;32m    212\u001B[0m     ):\n\u001B[0;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[1;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[1;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[1;32m    223\u001B[0m     )\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/sklearn/metrics/_classification.py:2204\u001B[0m, in \u001B[0;36mprecision_score\u001B[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001B[0m\n\u001B[1;32m   2037\u001B[0m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[1;32m   2038\u001B[0m     {\n\u001B[1;32m   2039\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray-like\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse matrix\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2064\u001B[0m     zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarn\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   2065\u001B[0m ):\n\u001B[1;32m   2066\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute the precision.\u001B[39;00m\n\u001B[1;32m   2067\u001B[0m \n\u001B[1;32m   2068\u001B[0m \u001B[38;5;124;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2202\u001B[0m \u001B[38;5;124;03m    array([0.5, 1. , 1. ])\u001B[39;00m\n\u001B[1;32m   2203\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 2204\u001B[0m     p, _, _, _ \u001B[38;5;241m=\u001B[39m \u001B[43mprecision_recall_fscore_support\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2205\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2206\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2207\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2208\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpos_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2209\u001B[0m \u001B[43m        \u001B[49m\u001B[43maverage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2210\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwarn_for\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprecision\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2211\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2212\u001B[0m \u001B[43m        \u001B[49m\u001B[43mzero_division\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mzero_division\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2213\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2214\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m p\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/sklearn/utils/_param_validation.py:186\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    184\u001B[0m global_skip_validation \u001B[38;5;241m=\u001B[39m get_config()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskip_parameter_validation\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m global_skip_validation:\n\u001B[0;32m--> 186\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    188\u001B[0m func_sig \u001B[38;5;241m=\u001B[39m signature(func)\n\u001B[1;32m    190\u001B[0m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/sklearn/metrics/_classification.py:1789\u001B[0m, in \u001B[0;36mprecision_recall_fscore_support\u001B[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001B[0m\n\u001B[1;32m   1626\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001B[39;00m\n\u001B[1;32m   1627\u001B[0m \n\u001B[1;32m   1628\u001B[0m \u001B[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1786\u001B[0m \u001B[38;5;124;03m array([2, 2, 2]))\u001B[39;00m\n\u001B[1;32m   1787\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1788\u001B[0m _check_zero_division(zero_division)\n\u001B[0;32m-> 1789\u001B[0m labels \u001B[38;5;241m=\u001B[39m \u001B[43m_check_set_wise_labels\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1791\u001B[0m \u001B[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001B[39;00m\n\u001B[1;32m   1792\u001B[0m samplewise \u001B[38;5;241m=\u001B[39m average \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msamples\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/sklearn/metrics/_classification.py:1561\u001B[0m, in \u001B[0;36m_check_set_wise_labels\u001B[0;34m(y_true, y_pred, average, labels, pos_label)\u001B[0m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m average \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m average_options \u001B[38;5;129;01mand\u001B[39;00m average \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   1559\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maverage has to be one of \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(average_options))\n\u001B[0;32m-> 1561\u001B[0m y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m \u001B[43m_check_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1562\u001B[0m \u001B[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001B[39;00m\n\u001B[1;32m   1563\u001B[0m \u001B[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001B[39;00m\n\u001B[1;32m   1564\u001B[0m present_labels \u001B[38;5;241m=\u001B[39m unique_labels(y_true, y_pred)\u001B[38;5;241m.\u001B[39mtolist()\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/sklearn/metrics/_classification.py:112\u001B[0m, in \u001B[0;36m_check_targets\u001B[0;34m(y_true, y_pred)\u001B[0m\n\u001B[1;32m    109\u001B[0m     y_type \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(y_type) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 112\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    113\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClassification metrics can\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt handle a mix of \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m targets\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    114\u001B[0m             type_true, type_pred\n\u001B[1;32m    115\u001B[0m         )\n\u001B[1;32m    116\u001B[0m     )\n\u001B[1;32m    118\u001B[0m \u001B[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001B[39;00m\n\u001B[1;32m    119\u001B[0m y_type \u001B[38;5;241m=\u001B[39m y_type\u001B[38;5;241m.\u001B[39mpop()\n",
      "\u001B[0;31mValueError\u001B[0m: Classification metrics can't handle a mix of multilabel-indicator and binary targets"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Наивный Байес (Наивный байесовский классификатор)\n",
   "id": "476ca4f74d041d25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "(\n",
    "    y_nb_bow_pred_train,\n",
    "    y_nb_bow_pred_test,\n",
    "    y_nb_bow_pred_proba_train,\n",
    "    y_nb_bow_pred_proba_test\n",
    ") = train_and_predict_toxicity(\n",
    "    model=MultinomialNB(),\n",
    "    X_train=X_train_bow,\n",
    "    X_test=X_test_bow,\n",
    "    y_train=y_train,\n",
    ")"
   ],
   "id": "a1ccc6e5d63eba01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "show_metrics(\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    y_pred_train=y_nb_bow_pred_train,\n",
    "    y_pred_test=y_nb_bow_pred_test,\n",
    "    y_pred_proba_train=y_nb_bow_pred_proba_train,\n",
    "    y_pred_proba_test=y_nb_bow_pred_proba_test,\n",
    "    title='MultinomialNB BoW'\n",
    ")"
   ],
   "id": "6ecb58bb2228a0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Обучение с TF-IDF",
   "id": "1e79b62ad9e3477"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train_tfidf, X_test_tfidf = get_tfidf(X_train, X_test)",
   "id": "8695c0b5fac3b9b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Логистическая регрессия",
   "id": "9b194eae2310d7f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "(\n",
    "    y_log_reg_tfidf_pred_train,\n",
    "    y_log_reg_tfidf_pred_test,\n",
    "    y_log_reg_tfidf_pred_proba_train,\n",
    "    y_log_reg_tfidf_pred_proba_test\n",
    ") = train_and_predict_toxicity(\n",
    "    model=LogisticRegression(max_iter=1000),\n",
    "    X_train=X_train_tfidf,\n",
    "    X_test=X_test_tfidf,\n",
    "    y_train=y_train,\n",
    ")"
   ],
   "id": "a9dd960afb137096",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "show_metrics(\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    y_pred_train=y_log_reg_tfidf_pred_train,\n",
    "    y_pred_test=y_log_reg_tfidf_pred_test,\n",
    "    y_pred_proba_train=y_log_reg_tfidf_pred_proba_train,\n",
    "    y_pred_proba_test=y_log_reg_tfidf_pred_proba_test,\n",
    "    title='LogisticRegression TF-IDF'\n",
    ")"
   ],
   "id": "28c8b57ff5b31d8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SVM",
   "id": "2ccaa045481643f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "(\n",
    "    y_linear_svc_tfidf_pred_train,\n",
    "    y_linear_svc_tfidf_pred_test,\n",
    "    y_linear_svc_tfidf_pred_proba_train,\n",
    "    y_linear_svc_tfidf_pred_proba_test\n",
    ") = train_and_predict_toxicity(\n",
    "    model=LinearSVC(dual=False),\n",
    "    X_train=X_train_tfidf,\n",
    "    X_test=X_test_tfidf,\n",
    "    y_train=y_train,\n",
    ")"
   ],
   "id": "909ebac2c947f73e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "show_metrics(\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    y_pred_train=y_linear_svc_tfidf_pred_train,\n",
    "    y_pred_test=y_linear_svc_tfidf_pred_test,\n",
    "    y_pred_proba_train=y_linear_svc_tfidf_pred_proba_train,\n",
    "    y_pred_proba_test=y_linear_svc_tfidf_pred_proba_test,\n",
    "    title='SVM TF-IDF'\n",
    ")"
   ],
   "id": "a88715034c530cb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Наивный Байес\n",
   "id": "ece56aa7d0be83a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "(\n",
    "    y_nb_tfidf_pred_train,\n",
    "    y_nb_tfidf_pred_test,\n",
    "    y_nb_tfidf_pred_proba_train,\n",
    "    y_nb_tfidf_pred_proba_test\n",
    ") = train_and_predict_toxicity(\n",
    "    model=MultinomialNB(),\n",
    "    X_train=X_train_tfidf,\n",
    "    X_test=X_test_tfidf,\n",
    "    y_train=y_train,\n",
    ")"
   ],
   "id": "bad4a434900e1487",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "show_metrics(\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    y_pred_train=y_nb_tfidf_pred_train,\n",
    "    y_pred_test=y_nb_tfidf_pred_test,\n",
    "    y_pred_proba_train=y_nb_tfidf_pred_proba_train,\n",
    "    y_pred_proba_test=y_nb_tfidf_pred_proba_test,\n",
    "    title='MultinomialNB TF-IDF'\n",
    ")"
   ],
   "id": "5f5e8de6a24db98c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Multi-Label классификация\n",
   "id": "4d072fb7579c89c6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Обучение моделей\n",
   "id": "42c9d79e80ebc261"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T07:25:28.463752Z",
     "start_time": "2024-12-03T07:25:28.271681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels = df[['toxicity_b', 'severe_toxicity_b', 'obscene_b', 'identity_attack_b', 'insult_b', 'threat_b', 'sexual_explicit_b']]\n",
    "\n",
    "X = df['ctws']\n",
    "y = labels"
   ],
   "id": "611c2f14bcaea031",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T07:25:39.516197Z",
     "start_time": "2024-12-03T07:25:39.169817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ],
   "id": "cdf85a669d276050",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def train_and_predict_toxicity_multilabel(model, X_train, X_test, y_train):\n",
    "    ovr = OneVsRestClassifier(model, n_jobs=-1)\n",
    "    ovr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_train = ovr.predict(X_train)\n",
    "    y_pred_test = ovr.predict(X_test)\n",
    "\n",
    "    return y_pred_train, y_pred_test\n",
    "\n",
    "def show_classification_report(y_train, y_test, y_pred_train, y_pred_test, target_names, title):\n",
    "    report_train = classification_report(y_train, y_pred_train, target_names=target_names, zero_division=0, output_dict=True)\n",
    "    report_test = classification_report(y_test, y_pred_test, target_names=target_names, zero_division=0, output_dict=True)\n",
    "\n",
    "    report_train_df = pd.DataFrame(report_train).transpose()\n",
    "    report_test_df = pd.DataFrame(report_test).transpose()\n",
    "\n",
    "    print(f\"{title}\\n\")\n",
    "\n",
    "    print(\"METRICS PER CLASS\\n\")\n",
    "    print(\"Train:\")\n",
    "    display(report_train_df.iloc[:-4, :])\n",
    "    print(\"\\nTest:\")\n",
    "    display(report_test_df.iloc[:-4, :])\n",
    "\n",
    "    print(\"\\nOVERALL METRICS\\n\")\n",
    "    print(\"Train:\")\n",
    "    display(report_train_df.loc[[\"micro avg\", \"macro avg\", \"weighted avg\", \"samples avg\"]].drop(columns=['support']))\n",
    "    print(\"\\nTest:\")\n",
    "    display(report_test_df.loc[[\"micro avg\", \"macro avg\", \"weighted avg\", \"samples avg\"]].drop(columns=['support']))\n",
    "\n",
    "    def show_heatmap(report_df, ax, model_name, sample_name):\n",
    "        heatmap_df = report_df.iloc[:-4, :]\n",
    "\n",
    "        sns.heatmap(heatmap_df.iloc[:, :-1], annot=True, cmap=\"Blues\", fmt=\".2f\", cbar=True, linewidths=0.5, ax=ax)\n",
    "        ax.set_title(f\"{model_name} Classification Report Heatmap ({sample_name})\", fontsize=16)\n",
    "        ax.set_ylabel(\"Classes\", fontsize=12)\n",
    "        ax.set_xlabel(\"Metrics\", fontsize=12)\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "        ax.tick_params(axis='y', rotation=0)\n",
    "\n",
    "    _, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "    show_heatmap(report_train_df, axes[0], title, \"Train\")\n",
    "    show_heatmap(report_test_df, axes[1], title, \"Test\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "fde3f105c7ce5949",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Обучение с мешком слов\n",
   "id": "ff8134c5e8e8d8ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train_bow, X_test_bow = get_bows(X_train, X_test)",
   "id": "5cca135212378099",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Логистическая регрессия",
   "id": "72ac4f0145a4161b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_log_reg_bow_pred_train, y_log_reg_bow_pred_test = train_and_predict_toxicity_multilabel(\n",
    "    model=LogisticRegression(max_iter=1000),\n",
    "    X_train=X_train_bow,\n",
    "    X_test=X_test_bow,\n",
    "    y_train=y_train,\n",
    ")"
   ],
   "id": "5cab0a93f12d871e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "show_classification_report(\n",
    "    y_train,\n",
    "    y_test,\n",
    "    y_log_reg_bow_pred_train,\n",
    "    y_log_reg_bow_pred_test,\n",
    "    y.columns,\n",
    "    'Multi-Label LogisticRegression BoW'\n",
    ")"
   ],
   "id": "356faaa1e4a95ab2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SVM",
   "id": "c14d9fa6025d1148"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_svm_bow_pred_train, y_svm_bow_pred_test = train_and_predict_toxicity_multilabel(\n",
    "    model=LinearSVC(dual=False),\n",
    "    X_train=X_train_bow,\n",
    "    X_test=X_test_bow,\n",
    "    y_train=y_train,\n",
    ")"
   ],
   "id": "f907f886ab2dc34a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "show_classification_report(\n",
    "    y_train,\n",
    "    y_test,\n",
    "    y_svm_bow_pred_train,\n",
    "    y_svm_bow_pred_test,\n",
    "    y.columns,\n",
    "    'Multi-Label SVM BoW'\n",
    ")"
   ],
   "id": "4bc8d2b555db3dd6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Наивный Байес",
   "id": "2193cf5cf9ddc5d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_nb_bow_pred_train, y_nb_bow_pred_test = train_and_predict_toxicity_multilabel(\n",
    "    model=MultinomialNB(),\n",
    "    X_train=X_train_bow,\n",
    "    X_test=X_test_bow,\n",
    "    y_train=y_train,\n",
    ")"
   ],
   "id": "dd9e4429464ab274",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "show_classification_report(\n",
    "    y_train,\n",
    "    y_test,\n",
    "    y_nb_bow_pred_train,\n",
    "    y_nb_bow_pred_test,\n",
    "    y.columns,\n",
    "    'Multi-Label MultinomialNB BoW'\n",
    ")"
   ],
   "id": "8fe57da85c75ec94",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Обучение с TF-IDF",
   "id": "8396e86fc7d7a200"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T07:41:20.592317Z",
     "start_time": "2024-12-03T07:40:57.356838Z"
    }
   },
   "cell_type": "code",
   "source": "X_train_tfidf, X_test_tfidf = get_tfidf(X_train, X_test)",
   "id": "3c108923f534ff54",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Логистическая регрессия\n",
   "id": "e4cc3ee79e515077"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "y_log_reg_tfidf_pred_train, y_log_reg_tfidf_pred_test = train_and_predict_toxicity_multilabel(\n",
    "    model=LogisticRegression(max_iter=1000),\n",
    "    X_train=X_train_tfidf,\n",
    "    X_test=X_test_tfidf,\n",
    "    y_train=y_train,\n",
    ")"
   ],
   "id": "15a60d1441b6a3b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "show_classification_report(\n",
    "    y_train,\n",
    "    y_test,\n",
    "    y_log_reg_tfidf_pred_train,\n",
    "    y_log_reg_tfidf_pred_test,\n",
    "    y.columns,\n",
    "    'Multi-Label LogisticRegression TF-IDF'\n",
    ")"
   ],
   "id": "c251464ef8b1f27b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SVM",
   "id": "f23fb16d904cd9fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "y_svm_tfidf_pred_train, y_svm_tfidf_pred_test = train_and_predict_toxicity_multilabel(\n",
    "    model=LinearSVC(dual=False),\n",
    "    X_train=X_train_tfidf,\n",
    "    X_test=X_test_tfidf,\n",
    "    y_train=y_train,\n",
    ")"
   ],
   "id": "7ebcf7086e62d78d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "show_classification_report(\n",
    "    y_train,\n",
    "    y_test,\n",
    "    y_svm_tfidf_pred_train,\n",
    "    y_svm_tfidf_pred_test,\n",
    "    y.columns,\n",
    "    'Multi-Label SVM TF-IDF'\n",
    ")"
   ],
   "id": "201680a83ce67202"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Наивный Байес\n",
   "id": "3a760630ac4902ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "236941c5f02ae24"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
