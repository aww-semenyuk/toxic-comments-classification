1. Выбор метрик качества

Для оценки качества моделей были выбраны ключевые метрики, такие как F1-мера, точность (precision), полнота (recall) и ROC-AUC, что позволило учесть дисбаланс в датасете. Для задачи multilabel классификации сравнивалась Macro F1 и учитывался AUC, как показатель, на сколько хорошо модели различают отдельные классы.
Были построены графики ROC-AUC для наглядности демонстрации успешности той или иной модели


2. Feature engineering

Проведена предобработка текстовых данных, включающая токенизацию и векторизацию текстов с помощью мешка слов и TF-IDF.
Был создан дополнительный признак `ctws`, на котором модель и обучалась.


3. Обучение классических моделей классификации

Обучение проводилось в рамках одноклассовой и multilabel классификации
При обучении мы разбивали датасет на train, validate и test выборку используя подход Out-Of-Time (OOT)
Были обучены классические модели классификации, включая Logistic Regression, Linear SVC, Наивный Байес и модели градиентного бустинга(XGBoost).
Для повышения качества использовался подбор гиперпараметров.


4. Валидация и выбор модели

Результаты моделей валидировались на тестовой и валидационной выборке.
Среди классических моделей Logistic Regression и Linear SVC с TF-IDF векторизацией показали лучшие результаты, уступая бинарной классификации на классе toxicity. Более продвинутые алгоритмы, такие как XGBoost, демонстрируют лучший баланс между precision и recall, обеспечивая более высокую F1-метрику.
